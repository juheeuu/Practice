{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "eval_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h1, h2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(x_dim, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2, z_dim*2)\n",
    "        )\n",
    "        \n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(z_dim, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1, x_dim),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = torch.chunk(self.enc(x), 2, dim=-1)\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.dec(z), mu, log_var\n",
    "        \n",
    "    def sampling(self, mu, log_var):\n",
    "        # reparametrization trick\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.rand_like(std)\n",
    "        return mu + (eps * std)\n",
    "\n",
    "vae = VAE(x_dim=784, h1=512, h2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (enc): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       "  (dec): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=784, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, log_var):\n",
    "    # reconstruction loss : binary cross entropy \n",
    "    bce_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # kl divergence \n",
    "    kld_loss = 0.5 * torch.sum(torch.exp(log_var) + mu.pow(2) -1 - log_var)\n",
    "    return bce_loss + kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_ind, (data, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(BATCH_SIZE, -1)\n",
    "        recon_x, mu, log_var = vae(data)\n",
    "        loss = loss_fn(recon_x, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_ind % 200 == 0:\n",
    "            print('Train Epoch:{} [{}/{} ({:0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_ind*len(data), len(train_loader.dataset),\n",
    "                100*batch_ind/len(train_loader), loss.item()/len(data)))\n",
    "        \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss/len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(): \n",
    "    vae.eval()\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in eval_loader:\n",
    "#             data = data.cuda()\n",
    "            data = data.view(BATCH_SIZE, -1)\n",
    "            recon, mu, log_var = vae(data)\n",
    "            eval_loss += loss_fn(recon, data, mu, log_var)\n",
    "    eval_loss /= len(eval_loader.dataset)\n",
    "    print('====> Evaluation loss : {:.4f}'.format(eval_loss))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kakao/.pyenv/versions/3.6.2/envs/cs224/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1 [0/60000 (0.000000%)]\tLoss: 542.727656\n",
      "Train Epoch:1 [20000/60000 (33.333333%)]\tLoss: 170.813398\n",
      "Train Epoch:1 [40000/60000 (66.666667%)]\tLoss: 158.496592\n",
      "====> Epoch: 1 Average loss: 174.6615\n",
      "====> Evaluation loss : 157.3062\n",
      "Train Epoch:2 [0/60000 (0.000000%)]\tLoss: 151.796562\n",
      "Train Epoch:2 [20000/60000 (33.333333%)]\tLoss: 156.967754\n",
      "Train Epoch:2 [40000/60000 (66.666667%)]\tLoss: 144.931299\n",
      "====> Epoch: 2 Average loss: 153.3949\n",
      "====> Evaluation loss : 150.6160\n",
      "Train Epoch:3 [0/60000 (0.000000%)]\tLoss: 147.827490\n",
      "Train Epoch:3 [20000/60000 (33.333333%)]\tLoss: 139.362725\n",
      "Train Epoch:3 [40000/60000 (66.666667%)]\tLoss: 151.197852\n",
      "====> Epoch: 3 Average loss: 148.5896\n",
      "====> Evaluation loss : 146.7084\n",
      "Train Epoch:4 [0/60000 (0.000000%)]\tLoss: 141.929707\n",
      "Train Epoch:4 [20000/60000 (33.333333%)]\tLoss: 154.884258\n",
      "Train Epoch:4 [40000/60000 (66.666667%)]\tLoss: 149.121816\n",
      "====> Epoch: 4 Average loss: 145.8419\n",
      "====> Evaluation loss : 144.9691\n",
      "Train Epoch:5 [0/60000 (0.000000%)]\tLoss: 130.211338\n",
      "Train Epoch:5 [20000/60000 (33.333333%)]\tLoss: 147.025439\n",
      "Train Epoch:5 [40000/60000 (66.666667%)]\tLoss: 144.916875\n",
      "====> Epoch: 5 Average loss: 144.0589\n",
      "====> Evaluation loss : 143.7350\n",
      "Train Epoch:6 [0/60000 (0.000000%)]\tLoss: 136.610459\n",
      "Train Epoch:6 [20000/60000 (33.333333%)]\tLoss: 146.235898\n",
      "Train Epoch:6 [40000/60000 (66.666667%)]\tLoss: 151.454727\n",
      "====> Epoch: 6 Average loss: 142.7403\n",
      "====> Evaluation loss : 142.8901\n",
      "Train Epoch:7 [0/60000 (0.000000%)]\tLoss: 143.206582\n",
      "Train Epoch:7 [20000/60000 (33.333333%)]\tLoss: 141.734424\n",
      "Train Epoch:7 [40000/60000 (66.666667%)]\tLoss: 142.102666\n",
      "====> Epoch: 7 Average loss: 141.6540\n",
      "====> Evaluation loss : 141.8195\n",
      "Train Epoch:8 [0/60000 (0.000000%)]\tLoss: 138.877422\n",
      "Train Epoch:8 [20000/60000 (33.333333%)]\tLoss: 138.464941\n",
      "Train Epoch:8 [40000/60000 (66.666667%)]\tLoss: 142.817129\n",
      "====> Epoch: 8 Average loss: 140.6866\n",
      "====> Evaluation loss : 140.7355\n",
      "Train Epoch:9 [0/60000 (0.000000%)]\tLoss: 138.932422\n",
      "Train Epoch:9 [20000/60000 (33.333333%)]\tLoss: 142.008311\n",
      "Train Epoch:9 [40000/60000 (66.666667%)]\tLoss: 139.471904\n",
      "====> Epoch: 9 Average loss: 140.0557\n",
      "====> Evaluation loss : 140.7283\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 2)\n",
    "    sample = vae.dec(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.4138e-08, 3.0656e-08, 4.7158e-08,  ..., 5.6960e-08,\n",
       "           4.3091e-08, 5.1339e-08],\n",
       "          [1.0038e-07, 8.6859e-08, 5.5758e-08,  ..., 3.8091e-08,\n",
       "           2.8813e-08, 1.9932e-08],\n",
       "          [4.9212e-08, 7.8227e-08, 5.3864e-05,  ..., 7.4444e-06,\n",
       "           5.0379e-08, 9.6977e-08],\n",
       "          ...,\n",
       "          [3.2870e-08, 6.3056e-08, 4.6359e-10,  ..., 1.9546e-07,\n",
       "           1.6134e-07, 3.1015e-08],\n",
       "          [7.1825e-08, 4.9877e-08, 8.9575e-08,  ..., 8.3595e-08,\n",
       "           3.6791e-08, 2.9302e-08],\n",
       "          [4.3021e-08, 5.2267e-08, 5.0142e-08,  ..., 3.4810e-08,\n",
       "           5.1181e-08, 3.9937e-08]]],\n",
       "\n",
       "\n",
       "        [[[6.9971e-09, 5.6664e-09, 6.5575e-09,  ..., 5.3638e-09,\n",
       "           1.0317e-08, 5.0095e-09],\n",
       "          [8.2636e-09, 1.4489e-08, 1.0991e-08,  ..., 5.2961e-09,\n",
       "           5.0652e-09, 6.6957e-09],\n",
       "          [6.1588e-09, 8.7248e-09, 3.3624e-09,  ..., 1.1742e-08,\n",
       "           1.9984e-08, 9.5720e-09],\n",
       "          ...,\n",
       "          [3.9356e-09, 9.6632e-09, 1.1686e-05,  ..., 1.1293e-05,\n",
       "           4.3716e-06, 8.9635e-09],\n",
       "          [4.5760e-09, 7.5199e-09, 7.4002e-09,  ..., 1.5999e-05,\n",
       "           7.0682e-09, 7.4084e-09],\n",
       "          [7.7117e-09, 1.4026e-08, 1.1820e-08,  ..., 3.9149e-09,\n",
       "           1.2298e-08, 7.3691e-09]]],\n",
       "\n",
       "\n",
       "        [[[2.6718e-12, 1.9665e-13, 1.6142e-12,  ..., 1.4954e-12,\n",
       "           8.2615e-13, 5.3526e-13],\n",
       "          [4.0462e-12, 2.1923e-12, 1.3724e-12,  ..., 5.2989e-13,\n",
       "           2.2565e-13, 4.1572e-13],\n",
       "          [2.5511e-12, 2.3379e-12, 1.2986e-09,  ..., 1.7154e-04,\n",
       "           1.3832e-12, 5.5604e-12],\n",
       "          ...,\n",
       "          [1.2327e-12, 1.1337e-12, 1.6176e-12,  ..., 1.8457e-11,\n",
       "           1.7908e-13, 1.3093e-12],\n",
       "          [5.9527e-12, 5.7402e-13, 2.0980e-12,  ..., 8.0662e-11,\n",
       "           1.5014e-12, 6.3765e-13],\n",
       "          [9.3433e-13, 1.3166e-12, 5.9540e-13,  ..., 5.2608e-13,\n",
       "           3.0672e-12, 5.7185e-13]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[6.7222e-06, 7.3105e-06, 9.0864e-06,  ..., 7.6370e-06,\n",
       "           7.4611e-06, 1.0494e-05],\n",
       "          [7.6410e-06, 1.0257e-05, 8.9409e-06,  ..., 9.3965e-06,\n",
       "           7.1337e-06, 5.2945e-06],\n",
       "          [1.0501e-05, 8.5269e-06, 6.4366e-06,  ..., 9.6522e-06,\n",
       "           9.8981e-06, 1.2092e-05],\n",
       "          ...,\n",
       "          [7.1785e-06, 7.5622e-06, 2.5326e-05,  ..., 3.2359e-05,\n",
       "           1.8802e-05, 5.9685e-06],\n",
       "          [8.7727e-06, 1.1978e-05, 1.1180e-05,  ..., 3.7238e-05,\n",
       "           8.6493e-06, 8.9463e-06],\n",
       "          [9.9233e-06, 8.9637e-06, 1.0948e-05,  ..., 9.3703e-06,\n",
       "           7.6904e-06, 5.2504e-06]]],\n",
       "\n",
       "\n",
       "        [[[1.6212e-10, 5.8632e-11, 6.6955e-11,  ..., 8.5038e-11,\n",
       "           5.7445e-11, 5.0822e-11],\n",
       "          [1.9763e-10, 3.6290e-11, 7.6267e-11,  ..., 4.3479e-11,\n",
       "           1.8359e-11, 1.2179e-10],\n",
       "          [5.5737e-10, 1.9058e-10, 1.6016e-11,  ..., 3.6273e-06,\n",
       "           8.7923e-11, 3.1654e-10],\n",
       "          ...,\n",
       "          [1.1334e-10, 8.4042e-11, 6.9027e-07,  ..., 1.3280e-10,\n",
       "           5.0504e-11, 5.2329e-11],\n",
       "          [2.0005e-10, 4.7068e-11, 5.9840e-11,  ..., 1.7228e-10,\n",
       "           2.1223e-11, 9.2603e-11],\n",
       "          [6.2111e-11, 3.6674e-11, 1.2172e-11,  ..., 3.5186e-11,\n",
       "           7.3128e-11, 1.0323e-10]]],\n",
       "\n",
       "\n",
       "        [[[1.8595e-09, 8.5965e-10, 2.8433e-09,  ..., 1.3322e-09,\n",
       "           2.3352e-09, 2.3830e-09],\n",
       "          [2.4684e-09, 3.7676e-09, 3.4271e-09,  ..., 1.1994e-09,\n",
       "           1.7935e-09, 1.1029e-09],\n",
       "          [2.4250e-09, 3.3877e-09, 1.0831e-09,  ..., 7.1135e-10,\n",
       "           2.8635e-09, 3.1212e-09],\n",
       "          ...,\n",
       "          [8.6707e-10, 1.8393e-09, 4.1240e-07,  ..., 6.0006e-05,\n",
       "           4.7963e-05, 1.9342e-09],\n",
       "          [1.2224e-09, 1.3302e-09, 4.4363e-09,  ..., 1.7321e-07,\n",
       "           2.4899e-09, 1.6693e-09],\n",
       "          [1.9561e-09, 4.5079e-09, 3.8090e-09,  ..., 9.1216e-10,\n",
       "           4.5542e-09, 1.7246e-09]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.view(64, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
